{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Human Activity- Models.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSmeA1he-ZxG",
        "colab_type": "text"
      },
      "source": [
        "# Implementing different models on Expert generated models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiBOQ9-04XkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUTH2cSN4g9X",
        "colab_type": "text"
      },
      "source": [
        "# Getting Train and Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4wn7VE34d_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('UCI_HAR_dataset/csv_files/train.csv')\n",
        "test = pd.read_csv('UCI_HAR_dataset/csv_files/test.csv')\n",
        "print(train.shape, test.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CfIw5mY4d9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get X_train and y_train from csv files\n",
        "X_train = train.drop(['subject', 'Activity', 'ActivityName'], axis=1)\n",
        "y_train = train.ActivityName"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_X1KU774d7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get X_test and y_test from test csv file\n",
        "X_test = test.drop(['subject', 'Activity', 'ActivityName'], axis=1)\n",
        "y_test = test.ActivityName"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gIk4bsA4d5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('X_train and y_train : ({},{})'.format(X_train.shape, y_train.shape))\n",
        "print('X_test  and y_test  : ({},{})'.format(X_test.shape, y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nT6-ZaBx4wSp",
        "colab_type": "text"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmeVLImr4d3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels=['LAYING', 'SITTING','STANDING','WALKING','WALKING_DOWNSTAIRS','WALKING_UPSTAIRS']\n",
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "plt.rcParams[\"font.family\"] = 'DejaVu Sans'\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fzDzYPb4d1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to run any model\n",
        "from datetime import datetime\n",
        "def perform_model(model, X_train, y_train, X_test, y_test, class_labels, cm_normalize=True, \\\n",
        "                 print_cm=True, cm_cmap=plt.cm.Greens):\n",
        "    \n",
        "    \n",
        "    # to store results at various phases\n",
        "    results = dict()\n",
        "    \n",
        "    # time at which model starts training \n",
        "    train_start_time = datetime.now()\n",
        "    print('training the model..')\n",
        "    model.fit(X_train, y_train)\n",
        "    print('Done \\n \\n')\n",
        "    train_end_time = datetime.now()\n",
        "    results['training_time'] =  train_end_time - train_start_time\n",
        "    print('training_time(HH:MM:SS.ms) - {}\\n\\n'.format(results['training_time']))\n",
        "    \n",
        "    \n",
        "    # predict test data\n",
        "    print('Predicting test data')\n",
        "    test_start_time = datetime.now()\n",
        "    y_pred = model.predict(X_test)\n",
        "    test_end_time = datetime.now()\n",
        "    print('Done \\n \\n')\n",
        "    results['testing_time'] = test_end_time - test_start_time\n",
        "    print('testing time(HH:MM:SS:ms) - {}\\n\\n'.format(results['testing_time']))\n",
        "    results['predicted'] = y_pred\n",
        "   \n",
        "\n",
        "    # calculate overall accuracty of the model\n",
        "    accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "    # store accuracy in results\n",
        "    results['accuracy'] = accuracy\n",
        "    print('---------------------')\n",
        "    print('|      Accuracy      |')\n",
        "    print('---------------------')\n",
        "    print('\\n    {}\\n\\n'.format(accuracy))\n",
        "    \n",
        "    \n",
        "    # confusion matrix\n",
        "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "    results['confusion_matrix'] = cm\n",
        "    if print_cm: \n",
        "        print('--------------------')\n",
        "        print('| Confusion Matrix |')\n",
        "        print('--------------------')\n",
        "        print('\\n {}'.format(cm))\n",
        "        \n",
        "    # plot confusin matrix\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.grid(b=False)\n",
        "    plot_confusion_matrix(cm, classes=class_labels, normalize=True, title='Normalized confusion matrix', cmap = cm_cmap)\n",
        "    plt.show()\n",
        "    \n",
        "    # get classification report\n",
        "    print('-------------------------')\n",
        "    print('| Classifiction Report |')\n",
        "    print('-------------------------')\n",
        "    classification_report = metrics.classification_report(y_test, y_pred)\n",
        "    # store report in results\n",
        "    results['classification_report'] = classification_report\n",
        "    print(classification_report)\n",
        "    \n",
        "    # add the trained  model to the results\n",
        "    results['model'] = model\n",
        "    \n",
        "    return results\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBNIpbQt4dyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# method for performing grid search\n",
        "def print_grid_search_attributes(model):\n",
        "    # Estimator that gave highest score among all the estimators formed in GridSearch\n",
        "    print('--------------------------')\n",
        "    print('|      Best Estimator     |')\n",
        "    print('--------------------------')\n",
        "    print('\\n\\t{}\\n'.format(model.best_estimator_))\n",
        "\n",
        "\n",
        "    # parameters that gave best results while performing grid search\n",
        "    print('--------------------------')\n",
        "    print('|     Best parameters     |')\n",
        "    print('--------------------------')\n",
        "    print('\\tParameters of best estimator : \\n\\n\\t{}\\n'.format(model.best_params_))\n",
        "\n",
        "\n",
        "    #  number of cross validation splits\n",
        "    print('---------------------------------')\n",
        "    print('|   No of CrossValidation sets   |')\n",
        "    print('--------------------------------')\n",
        "    print('\\n\\tTotal numbre of cross validation sets: {}\\n'.format(model.n_splits_))\n",
        "\n",
        "\n",
        "    # Average cross validated score of the best estimator, from the Grid Search \n",
        "    print('--------------------------')\n",
        "    print('|        Best Score       |')\n",
        "    print('--------------------------')\n",
        "    print('\\n\\tAverage Cross Validate scores of best estimator : \\n\\n\\t{}\\n'.format(model.best_score_))\n",
        "\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Uz-z0sd5KjB",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression with Grid search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dKFNQkd4dv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G30OpKuN4dtK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# start Grid search\n",
        "parameters = {'C':[0.01, 0.1, 1, 10, 20, 30], 'penalty':['l2','l1']}\n",
        "log_reg = linear_model.LogisticRegression()\n",
        "log_reg_grid = GridSearchCV(log_reg, param_grid=parameters, cv=3, verbose=1, n_jobs=-1)\n",
        "log_reg_grid_results =  perform_model(log_reg_grid, X_train, y_train, X_test, y_test, class_labels=labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IehSn4To4dq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "plt.grid(b=False)\n",
        "plot_confusion_matrix(log_reg_grid_results['confusion_matrix'], classes=labels, cmap=plt.cm.Greens, )\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPd_fbrE4dpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# observe the attributes of the model \n",
        "print_grid_search_attributes(log_reg_grid_results['model'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CzUVddS5gRE",
        "colab_type": "text"
      },
      "source": [
        "# Linear SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgaDeDbX4dmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import LinearSVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WysPj3Sd4dlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = {'C':[0.125, 0.5, 1, 2, 8, 16]}\n",
        "lr_svc = LinearSVC(tol=0.00005)\n",
        "lr_svc_grid = GridSearchCV(lr_svc, param_grid=parameters, n_jobs=-1, verbose=1)\n",
        "lr_svc_grid_results = perform_model(lr_svc_grid, X_train, y_train, X_test, y_test, class_labels=labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vCyhTm04dif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print_grid_search_attributes(lr_svc_grid_results['model'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI-wd3lD5nmv",
        "colab_type": "text"
      },
      "source": [
        "# SVM with rbf kernel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHgsBraq4dgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "parameters = {'C':[2,8,16],\\\n",
        "              'gamma': [ 0.0078125, 0.125, 2]}\n",
        "rbf_svm = SVC(kernel='rbf')\n",
        "rbf_svm_grid = GridSearchCV(rbf_svm,param_grid=parameters, n_jobs=-1)\n",
        "rbf_svm_grid_results = perform_model(rbf_svm_grid, X_train, y_train, X_test, y_test, class_labels=labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwhC9_7i4det",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print_grid_search_attributes(rbf_svm_grid_results['model'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5nwVZ6N5tfm",
        "colab_type": "text"
      },
      "source": [
        "# Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ_U_Muo4dbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "parameters = {'max_depth':np.arange(3,10,2)}\n",
        "dt = DecisionTreeClassifier()\n",
        "dt_grid = GridSearchCV(dt,param_grid=parameters, n_jobs=-1)\n",
        "dt_grid_results = perform_model(dt_grid, X_train, y_train, X_test, y_test, class_labels=labels)\n",
        "print_grid_search_attributes(dt_grid_results['model'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btX4rZPQ5vx-",
        "colab_type": "text"
      },
      "source": [
        "# Random Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N4vxodR4dZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "params = {'n_estimators': np.arange(10,201,20), 'max_depth':np.arange(3,15,2)}\n",
        "rfc = RandomForestClassifier()\n",
        "rfc_grid = GridSearchCV(rfc, param_grid=params, n_jobs=-1)\n",
        "rfc_grid_results = perform_model(rfc_grid, X_train, y_train, X_test, y_test, class_labels=labels)\n",
        "print_grid_search_attributes(rfc_grid_results['model'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsUORKC554Yg",
        "colab_type": "text"
      },
      "source": [
        "# Gradient Boosted Decision tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knuRdI_S5-HD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "param_grid = {'max_depth': np.arange(5,8,1), \\\n",
        "             'n_estimators':np.arange(130,170,10)}\n",
        "gbdt = GradientBoostingClassifier()\n",
        "gbdt_grid = GridSearchCV(gbdt, param_grid=param_grid, n_jobs=-1)\n",
        "gbdt_grid_results = perform_model(gbdt_grid, X_train, y_train, X_test, y_test, class_labels=labels)\n",
        "print_grid_search_attributes(gbdt_grid_results['model'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK3LqNIe5_Lj",
        "colab_type": "text"
      },
      "source": [
        "# Comparing all the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8labPKFT6Mf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('\\n                     Accuracy     Error')\n",
        "print('                     ----------   --------')\n",
        "print('Logistic Regression : {:.04}%       {:.04}%'.format(log_reg_grid_results['accuracy'] * 100,\\\n",
        "                                                  100-(log_reg_grid_results['accuracy'] * 100)))\n",
        "\n",
        "print('Linear SVC          : {:.04}%       {:.04}% '.format(lr_svc_grid_results['accuracy'] * 100,\\\n",
        "                                                        100-(lr_svc_grid_results['accuracy'] * 100)))\n",
        "\n",
        "print('rbf SVM classifier  : {:.04}%      {:.04}% '.format(rbf_svm_grid_results['accuracy'] * 100,\\\n",
        "                                                          100-(rbf_svm_grid_results['accuracy'] * 100)))\n",
        "\n",
        "print('DecisionTree        : {:.04}%      {:.04}% '.format(dt_grid_results['accuracy'] * 100,\\\n",
        "                                                        100-(dt_grid_results['accuracy'] * 100)))\n",
        "\n",
        "print('Random Forest       : {:.04}%      {:.04}% '.format(rfc_grid_results['accuracy'] * 100,\\\n",
        "                                                           100-(rfc_grid_results['accuracy'] * 100)))\n",
        "print('GradientBoosting DT : {:.04}%      {:.04}% '.format(rfc_grid_results['accuracy'] * 100,\\\n",
        "                                                        100-(rfc_grid_results['accuracy'] * 100)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}